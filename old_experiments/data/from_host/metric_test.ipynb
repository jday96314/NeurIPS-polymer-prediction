{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b5b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "# These values are from the train data.\n",
    "MINMAX_DICT =  {\n",
    "        'Tg': [-148.0297376, 472.25],\n",
    "        'FFV': [0.2269924, 0.77709707],\n",
    "        'Tc': [0.0465, 0.524],\n",
    "        'Density': [0.748691234, 1.840998909],\n",
    "        'Rg': [9.7283551, 34.672905605],\n",
    "    }\n",
    "NULL_FOR_SUBMISSION = -9999\n",
    "\n",
    "\n",
    "def scaling_error(labels, preds, property):\n",
    "    error = np.abs(labels - preds)\n",
    "    min_val, max_val = MINMAX_DICT[property]\n",
    "    label_range = max_val - min_val\n",
    "    return np.mean(error / label_range)\n",
    "\n",
    "\n",
    "def get_property_weights(labels):\n",
    "    property_weight = []\n",
    "    for property in MINMAX_DICT.keys():\n",
    "        valid_num = np.sum(labels[property] != NULL_FOR_SUBMISSION)\n",
    "        property_weight.append(valid_num)\n",
    "    property_weight = np.array(property_weight)\n",
    "    property_weight = np.sqrt(1 / property_weight)\n",
    "    return (property_weight / np.sum(property_weight)) * len(property_weight)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute weighted Mean Absolute Error (wMAE) for the Open Polymer challenge.\n",
    "\n",
    "    Expected input:\n",
    "      - solution and submission as pandas.DataFrame\n",
    "      - Column 'id': unique identifier for each sequence\n",
    "      - Columns 'Tg', 'FFV', 'Tc', 'Density', 'Rg' as the predicted targets\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> solution = pd.DataFrame({'id': range(4), 'Tg': [0.2]*4, 'FFV': [0.2]*4, 'Tc': [0.2]*4, 'Density': [0.2]*4, 'Rg': [0.2]*4})\n",
    "    >>> submission = pd.DataFrame({'id': range(4), 'Tg': [0.5]*4, 'FFV': [0.5]*4, 'Tc': [0.5]*4, 'Density': [0.5]*4, 'Rg': [0.5]*4})\n",
    "    >>> round(score(solution, submission, row_id_column_name=row_id_column_name), 4)\n",
    "    0.2922\n",
    "    >>> submission = pd.DataFrame({'id': range(4), 'Tg': [0.2]*4, 'FFV': [0.2]*4, 'Tc': [0.2]*4, 'Density': [0.2]*4, 'Rg': [0.2]*4} )\n",
    "    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n",
    "    0.0\n",
    "    \"\"\"\n",
    "    chemical_properties = list(MINMAX_DICT.keys())\n",
    "    property_maes = []\n",
    "    property_weights = get_property_weights(solution[chemical_properties])\n",
    "    for property in chemical_properties:\n",
    "        is_labeled = solution[property] != NULL_FOR_SUBMISSION\n",
    "        property_maes.append(scaling_error(solution.loc[is_labeled, property], submission.loc[is_labeled, property], property))\n",
    "\n",
    "    if len(property_maes) == 0:\n",
    "        raise RuntimeError('No labels')\n",
    "    return float(np.average(property_maes, weights=property_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2c090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_weights(csv_path, target_names):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    scale_normalization_factors = []\n",
    "    sample_count_normalization_factors = []\n",
    "    for target in target_names:\n",
    "        target_values = df[target].values\n",
    "        target_values = target_values[~np.isnan(target_values)]\n",
    "\n",
    "        scale_normalization_factors.append(1 / (max(target_values) - min(target_values)))\n",
    "        sample_count_normalization_factors.append((1/len(target_values))**0.5)\n",
    "\n",
    "    scale_normalization_factors = np.array(scale_normalization_factors)\n",
    "    sample_count_normalization_factors = np.array(sample_count_normalization_factors)\n",
    "\n",
    "    target_weights = scale_normalization_factors * len(target_names) * sample_count_normalization_factors / sum(sample_count_normalization_factors)\n",
    "\n",
    "    return target_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('train.csv')\n",
    "\n",
    "fake_submission_records = []\n",
    "for _, row in labels_df.iterrows():\n",
    "    for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
